{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>We are Caktus Group.</p> <p>This is our team's documentation. It is a living repository that everyone at Caktus may edit. To make a change or suggestion, simply click the pencil icon in the top right of any page.</p>"},{"location":"getting-started/","title":"Developer On-boarding","text":"<p>This documentation is meant for new developers at Caktus Consulting Group. It describes our particular setup and development workflow. It is not meant as a prescription but as a path that is well tested and known to work. Of course there are some steps, which if not followed, will result in an inability to use or  access services, or result in a difficult time seeking help from your fellow developers. So if you know the  consequences of straying from the Golden Path feel free to play around with these setup steps. If you are  fresh-faced and apple cheeked, best to follow exactly.</p> <p>See you on the other side and happy coding.</p>"},{"location":"getting-started/#caktus-golden-path","title":"Caktus' \"Golden Path\"","text":"<p>Note</p> <p>Assumptions about what is or is not \"Golden Path\", or even if it is a good idea to have a Golden Path, were made solely by me (Jeremy Gibson). Today. During shipit.</p> <p>We (okay I) have stolen the idea of the Golden Path from a Spotify blog post. The idea is, as they put it in their post, that:</p> <p>Quote</p> <p>This is the way we support an easy and streamlined way of working. If you are an adventurer you can of course leave the Golden Path and do your own thing, but then you will not have the same support.</p>"},{"location":"getting-started/#core-stack","title":"Core Stack","text":"<p>The following are the primary technologies that we use right now.</p> <ol> <li>Python</li> <li>Django</li> <li>Wagtail</li> <li>PostgreSQL</li> <li>Ansible</li> <li>React </li> <li>Kubernetes</li> <li>AWS</li> </ol> <p> (Google Drawing)</p>"},{"location":"getting-started/#support-stack","title":"Support Stack","text":"<p>hic sunt dracones</p> <p>This is where those of you who feel like striking off from the Golden Path would typically do so. </p> <p>This stack is more fungible than the core stack and may change, or may not even apply. </p> <p>If you are working on a project that comes from jade-truffle, then these will be assumed.  </p> <ol> <li>direnv</li> <li>pip-tools </li> <li>pyenv</li> <li>nvm</li> <li>invoke-kubesae</li> <li>Docker</li> </ol>"},{"location":"getting-started/#experimental-stack","title":"Experimental Stack","text":"<ol> <li>Poetry</li> <li>PDM</li> </ol>"},{"location":"getting-started/#recommended-setup-path","title":"Recommended Setup Path","text":"<p>Note</p> <p>If you have an M1 start there.</p> <ol> <li>M1</li> <li>AWS Setup</li> <li>Kubernetes Setup</li> </ol>"},{"location":"getting-started/AWS/","title":"AWS Setup","text":"<p>AWS is a core component of our deployment and management stack. We use it for just about everything.</p>"},{"location":"getting-started/AWS/#steps","title":"Steps","text":""},{"location":"getting-started/AWS/#obtain-an-aws-account-from-tech-support","title":"Obtain an AWS account from Tech Support","text":"<p>You can go about this in various ways. Politely request to be given an AWS use account.</p> <ol> <li>Email: <code>support@caktusgroup.com</code></li> <li>Slack: <code>#sysadmin</code> channel.</li> </ol>"},{"location":"getting-started/AWS/#obtain-your-credentials-from-your-account","title":"Obtain your credentials from your account.","text":"<ol> <li>Sign into https://caktus.signin.aws.amazon.com/console</li> <li>Using the credentials provided, setup Mulit-Factor Authentication.</li> <li>Navigate to your Security Credentials</li> <li>Click <code>Create Access Key</code></li> </ol> <p>Warning</p> <p>Be sure that you download the csv offered to you in the confirmation modal, otherwise you will need to re-do it as you won't have another opportunity to read the secret key.</p>"},{"location":"getting-started/AWS/#setup-aws-command-line","title":"Setup AWS command line","text":"<p>Note</p> <p>Some projects have <code>awscli</code> installed as a pip dependency. If so, you will have <code>1.n.n</code> version of AWS cli. If you install using the below instructions, you will have <code>2.n.n</code> version. This is not a problem both are supported. V2 has some extra sugar that's all.</p>"},{"location":"getting-started/AWS/#install-the-cli","title":"Install the CLI","text":"<p>Follow the Install the CLI instructions for your machine. </p> <p>Are you on an M1? Have you followed the blog post yet?</p>"},{"location":"getting-started/AWS/#verify-your-installation","title":"Verify your installation","text":"<pre><code>    (prompt)$ which aws\n</code></pre> <p>That should read something like <code>/usr/local/bin/aws</code></p> <pre><code>    (prompt)$ aws --version\n</code></pre> <p>That should be something like <code>aws-cli/2.n.n ...</code></p>"},{"location":"getting-started/AWS/#configure-aws-command-line","title":"Configure AWS command line","text":"<p>Note</p> <p>Caktus uses an AWS assume role to grant access to the resouces necessary to manage our projects. Project specific documentation and <code>arn</code>s can be found here</p>"},{"location":"getting-started/AWS/#create-the-directories-and-files-for-aws","title":"Create the directories and files for AWS","text":"<pre><code>    (prompt)$ mkdir ~/.aws\n    (prompt)$ touch ~/.aws/credentials\n    (prompt)$ touch ~/.aws/config\n</code></pre>"},{"location":"getting-started/AWS/#set-profile-and-credentials","title":"Set profile and credentials","text":"<p>You will need a primary profile named <code>caktus</code> in your <code>config</code> and <code>credentials</code> file</p> <pre><code>    # ~/.aws/config\n[profile caktus]\nregion = us-east-1\n</code></pre> <pre><code>    # ~/.aws/credentials\n[caktus]\naws_access_key_id = &lt;SECRET KEY FROM THE CSV YOU DOWNLOADED&gt;\n    aws_secret_access_key = &lt;SECRET ACCESS KEY FROM THE CSV YOU DOWNLOADED&gt;\n</code></pre>"},{"location":"getting-started/AWS/#project-profiles","title":"Project Profiles","text":"<p>Each project will have an Role ARN that you will use to access your projects.  For each project you work on you will need a <code>config</code> and <code>credentials</code> entry.</p> <pre><code>    # ~/.aws/config\n\n[profile my-caktus-project]\nregion = &lt;project-region&gt; </code></pre> <pre><code>    # ~/.aws/credentials\n[caktus]\naws_access_key_id = &lt;SECRET KEY FROM THE CSV YOU DOWNLOADED&gt;\n    aws_secret_access_key = &lt;SECRET ACCESS KEY FROM THE CSV YOU DOWNLOADED&gt;\n\n    ...\n\n    [my-caktus-project]\nrole_arn = &lt;ARN FROM THE ABOVE \"Role Arn\" LINK&gt;\n    source_profile = caktus\n</code></pre>"},{"location":"getting-started/AWS/#test-your-access","title":"Test your access","text":"<p>To make sure you have everything set up correctly, test your access:</p> <pre><code>    (prompt)$ export AWS_PROFILE=my-caktus-project\n    (prompt)$ aws s3 ls\n</code></pre> <p>Depending on whether or not the project has S3 buckets you should see a list of them. Regardless you should not see an error.</p>"},{"location":"getting-started/M1/","title":"The Apple M1 and M2","text":"<p>Historically our dev workflows and setup have revolved around x86 architecture. The M1 is  new and can be a bit of a problem setting up. As you work through this process, please update this doc with quirks, tricks, or best practices you come across.</p> <p>These instructions are currently the same for both M1 and M2.</p> <p>Warning</p> <p>As of the commit of this documentation, the following blog is the best place to start. Forge your own path at your and your colleagues risk. Right now it is very easy to get into a state where confusing things happen.</p> <p>Colin's blog post Python, Django, and React Development on Apple Silicon.</p> <p>Another post Django Development Environment on Apple M1</p>"},{"location":"getting-started/M1/#environment-setup","title":"Environment setup","text":""},{"location":"getting-started/M1/#rosetta-2-and-xcode","title":"Rosetta 2 and Xcode","text":"<p>First, make sure Rosetta 2 is installed. Rosetta 2 enables a Mac with Apple silicon to use apps built for a Mac with an Intel processor. Install it with:</p> <pre><code>softwareupdate --install-rosetta  --agree-to-license\n</code></pre> <p>Also, install Xcode's command-line tools for <code>python3</code> and other useful libraries:</p> <pre><code>xcode-select --install\n</code></pre>"},{"location":"getting-started/M1/#generating-a-new-ssh-key","title":"Generating a new SSH key","text":"<p>Follow GitHub's Generating a new SSH key and adding it to the ssh-agent instructions for these sections:</p> <ul> <li>Generating a new SSH key</li> <li>Adding your SSH key to the ssh-agent</li> </ul>"},{"location":"getting-started/M1/#ssh-agent","title":"ssh-agent","text":"<p>In MacOS Monterey (12.0) or later, you should use the <code>--apple-use-keychain</code> to add your SSH private key to the ssh-agent and store your passphrase in the keychain:</p> <pre><code>ssh-add --apple-use-keychain\n</code></pre>"},{"location":"getting-started/M1/#configure-git-name-and-email","title":"Configure Git name and email","text":"<p>GitHub uses your commit email address to associate commits with your account on GitHub.com. Follow these steps to link your git configuration to your GitHub account.</p> <p>First add, verify, and set as Primary your Caktus email on GitHub.</p> <p>To associate your <code>git</code> commits to your GitHub account, we will set your name and email address for every repository on your computer.</p> <ol> <li> <p>Set your name:</p> <pre><code>git config --global user.name \"Mona Lisa\"\n</code></pre> </li> <li> <p>Then set your email:</p> <pre><code>git config --global user.email \"mlisa@caktusgroup.com\"\n</code></pre> </li> </ol>"},{"location":"getting-started/M1/#homebrew","title":"Homebrew","text":"<p>Homebrew does support Apple Silicon.</p> <p>Install arm64 <code>brew</code> into <code>/opt/homebrew</code>:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>Then add <code>brew</code> to your PATH:</p> <pre><code>echo 'export PATH=\"/opt/homebrew/bin:$PATH\"' &gt;&gt; ~/.zshrc\n</code></pre> <p>Note</p> <p>It seems that Homebrew packages have now generally added support for arm64. However, it is possible that you may encounter a package that does not. If you find yourself in that scenario, it is possible to support running both native arm64 and x86-emulated homebrew packages, by installing an x86-emulated homebrew side-by-side. See Colin's blog post for an example.</p>"},{"location":"getting-started/M1/#install-openssl","title":"Install openssl","text":"<pre><code>brew install openssl\n</code></pre>"},{"location":"getting-started/M1/#starship-prompt","title":"Starship Prompt","text":"<p>Starship is a simple and customizable shell prompt. Follow the Quick Install instructions to get set up.</p> <p>Note</p> <p>Make sure to install a Nerd Font to render  glyph symbols (, ) properly. Then enable the font in your terminal:</p> <ul> <li>iTerm2: Open iTerm2 \u2192 Preferences \u2192 Profiles \u2192 Text and set Font to your Nerd Font.</li> <li>Visual Studio Code: Open Code \u2192 Preferences \u2192 Settings (Mac), enter <code>terminal.integrated.fontFamily</code> in the search box at the top of Settings ta and set the value below to your Nerd Font.</li> </ul>"},{"location":"getting-started/M1/#install-python","title":"Install Python","text":"<p>We recommend installing Python from the python.org Downloads page.</p> <p>After running through the installation, don't forget to double click on the Install Certificates.command icon in Finder (in the folder for the new Python installation) to install a set of SSL root certificates.</p> <p>Note</p> <p>You may instead use a Python manager (like pyenv) to manager versions of Python, if you prefer, though our experience with them has not been as good as downloading Python from python.org.</p>"},{"location":"getting-started/M1/#install-direnv","title":"Install direnv","text":"<p>Next install direnv, which will load/unload environment variables based on a <code>.envrc</code> file.</p> <pre><code>brew install direnv\n</code></pre> <p>In your user's Home directory create a file <code>.direnvrc</code></p> <pre><code>$&gt; touch ~/.direnvrc\n</code></pre> <p>Then edit that file and add the following to it using your favorite text editor, and add the following.</p> <pre><code>use_cluster() {\nkubectl config use-context \"$1\"\n}\n</code></pre> <p>Add the following lines to your <code>~/.zshrc</code>:</p> <pre><code>eval \"$(direnv hook zsh)\"\n</code></pre>"},{"location":"getting-started/M1/#install-postgresql","title":"Install PostgreSQL","text":"<p>Even if you don't run the PostgreSQL service, it can be helpful to install the CLI tools with:</p> <pre><code>HOMEBREW_NO_AUTO_UPDATE=1 brew install postgresql\n</code></pre> <p>Note</p> <p>See From Caktus With Love for more information on <code>HOMEBREW_NO_AUTO_UPDATE=1</code>.</p>"},{"location":"getting-started/M1/#install-docker","title":"Install Docker","text":"<p>Visit https://docs.docker.com/desktop/mac/install/ and click the Mac with Apple chip blue button, then:</p> <ol> <li>Once downloaded, copy the Docker application to your Applications folder</li> <li>Then open the Docker app in the Applications folder</li> </ol>"},{"location":"getting-started/M1/#currently-identified-additions-to-zshrc-for-m1-users","title":"Currently Identified Additions to .zshrc for M1 Users","text":"<pre><code>alias ibrew='arch -x86_64 /usr/local/bin/brew'\n\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"/opt/homebrew/opt/nvm/nvm.sh\" ] &amp;&amp; . \"/opt/homebrew/opt/nvm/nvm.sh\"  # This loads nvm\n[ -s \"/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm\" ] &amp;&amp; . \"/opt/homebrew/opt/nvm/etc/bash_completion.d/nvm\"  # This loads nvm bash_completion\n\nautoload -U add-zsh-hook\nload-nvmrc() {\nlocal node_version=\"$(nvm version)\"\nlocal nvmrc_path=\"$(nvm_find_nvmrc)\"\n\nif [ -n \"$nvmrc_path\" ]; then\nlocal nvmrc_node_version=$(nvm version \"$(cat \"${nvmrc_path}\")\")\n\nif [ \"$nvmrc_node_version\" = \"N/A\" ]; then\nnvm install\n    elif [ \"$nvmrc_node_version\" != \"$node_version\" ]; then\nnvm use\n    fi\nelif [ \"$node_version\" != \"$(nvm version default)\" ]; then\necho \"Reverting to nvm default version\"\nnvm use default\n  fi\n}\nadd-zsh-hook chpwd load-nvmrc\nload-nvmrc\n\n# Add homebrew to path\nexport PATH=\"/opt/homebrew/bin:$PATH\"\n\n# C-lib compilation flags\nexport LDFLAGS=\"-L$(brew --prefix openssl)/lib -L$(brew --prefix zlib)/lib\"\nexport CPPFLAGS=\"-I$(brew --prefix openssl)/include -I$(brew --prefix zlib)/include\"\n\n# Hook in direnv\neval \"$(direnv hook zsh)\"\n\n\nAfter adding this to your `.zshrc`, source the file to make it available to your current \nenvironment.\n\n```shell\n$&gt; source ~/.zshrc\n</code></pre>"},{"location":"getting-started/aws-vault/","title":"AWS Multi-factor Authentication on the Command Line using AWS-Vault","text":""},{"location":"getting-started/aws-vault/#slow-your-scroll-the-introduction","title":"Slow Your Scroll - The Introduction","text":"<p>Having some form of Multi-factor Authentication (MFA) enabled, be it sms, an authenticator app, or yubikey, is an important aspect of the account security policy that you enforce on your AWS Account. User Credentials (username and password) and MFA give users a higher degree of certainty that the AWS Console user accessing resources within the account is in fact who they say they are. As developers and system administrators it\\'s important that we extend this degree of certainty to the command line (cli) where we interact with aws resources programmatically using access keys. This can be done using aws-vault a cli tool to securely store and access AWS credentials in a development environment.</p>"},{"location":"getting-started/aws-vault/#to-install","title":"To Install","text":"<p>MacOS</p> <p><code>brew install --cask aws-vault</code></p> <p>Windows</p> <p><code>choco install aws-vault</code></p> <p>Linux</p> <p>please refer to install section of  aws-vault docs for your linux distribution</p>"},{"location":"getting-started/aws-vault/#getting-started-a-quick-look-at-the-aws-config-file","title":"Getting Started - A Quick Look at the AWS Config File","text":"<p>Open <code>~/.aws/config</code>.</p> <pre><code>; Caktus Managed AWS\n[profile caktus]\ncredential_process=aws-vault exec --no-session --json caktus\n\n[profile caktus-mfa]\nmfa_serial=arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;\nsource_profile=caktus\nregion=us-east-1\noutput=json\n\n; Assume Role setup\n[profile &lt;role-profile&gt;]\nmfa_serial=arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;\nrole_arn=arn:aws:iam::&lt;role-profile-account-id&gt;:role/&lt;assumed-role&gt;\nsource_profile=caktus\nregion=us-east-1\n\n[profile &lt;role-profile&gt;]\nmfa_serial=arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;\nrole_arn=arn:aws:iam::&lt;role-profile-account-id&gt;:role/&lt;assumed-role&gt;\nsource_profile=caktus\n</code></pre> <p>At the end of this setup you should have both a caktus profile and mfa profile for main account access listed in your aws config file. Assuming roles in other accounts should follow the above syntax that sets <code>caktus</code> as the <code>source_profile</code> for the <code>&lt;role_profile&gt;</code>. All MFA protected profiles need to have your <code>mfa_serial</code> specified for it. Both <code>Main Account setup</code> and <code>Assume Role setup</code> can be repeated as many times as needed. </p> <p>You will need to comment out (<code>;</code>) or delete an existing <code>caktus</code> profile to allow <code>aws-vault</code> to manage this profile in the config file. No changes are needed to be done to the credentials file.</p>"},{"location":"getting-started/aws-vault/#caktus-account-setup","title":"Caktus Account setup","text":"<ol> <li>Setup <code>caktus</code> by running     <code>aws-vault add caktus</code>.</li> </ol> <pre><code>$ aws-vault add caktus\nEnter Access Key ID: &lt;aws-access-key-id&gt; \nEnter Secret Access Key: &lt;aws-secret-access-key&gt; \nAdded credentials to profile \"caktus\" in vault\n</code></pre> <p>After providing your aws keys you will be prompted by KeyChain on MacOS to set a password. If you are on another operating system or would like to change the behavior of the vaulting backend please refer to this section of the docs.</p> <p>In the <code>~/.aws/config</code> file, you should see the newly created <code>caktus</code> profile.</p> <pre><code>[profile caktus]\n</code></pre> <ol> <li> <p>Set the <code>credentials_process</code> variable to instruct <code>aws-vault</code> to     expose the <code>caktus</code> profile's access keys to the terminal. <pre><code>[profile caktus]\ncredential_process=aws-vault exec --no-session --json caktus\n</code></pre></p> </li> <li> <p>Setup <code>caktus-mfa</code> in <code>~/.aws/config</code> file</p> </li> </ol> <pre><code>[profile caktus]\ncredential_process=aws-vault exec --no-session --json caktus\n\n[profile caktus-mfa]\nmfa_serial=arn:aws:iam::&lt;account-id&gt;:mfa/&lt;username&gt;\nsource_profile=caktus\nregion=us-east-1\noutput=json\n</code></pre> <p>Setting <code>mfa_serial</code> for the caktus-mfa profile: - Copy your IAM ARN for your user: <code>arn:aws:iam::&lt;caktus-account-id&gt;:user/&lt;username&gt;</code> - Replace <code>user</code> with <code>mfa</code>: <code>arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;</code></p> <p>The <code>caktus-mfa</code> profile's <code>source profile</code> should be set to <code>caktus</code>.</p> <p><code>caktus-mfa</code> can just be added to the aws config file. <code>aws-vault add caktus-mfa</code> is not used. (This is also true for <code>&lt;role-profile&gt;</code>s).</p> <ol> <li>Test the configuration</li> </ol> <pre><code>$ aws-vault exec caktus-mfa \nEnter MFA code for arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;: &lt;Enter Code from MFA Device&gt;\n# Now authenticated and aws-vault session has been created \n$ env | grep AWS\nAWS_VAULT=caktus-mfa\n...\n...\n...\n</code></pre> <ol> <li>Assuming Roles from the Caktus Account</li> </ol> <pre><code>[profile &lt;role-profile&gt;]\nmfa_serial=arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;\nrole_arn=arn:aws:iam::&lt;role-profile-account-id&gt;:role/&lt;assumed-role&gt;\nsource_profile=caktus\nregion=us-east-1\n</code></pre> <p>Asumming roles will follow the above pattern. Check with the lead developer for the particular project you are joining to get the <code>&lt;role-profile-account-id&gt;</code> and <code>&lt;assumed-role&gt;</code> that you will be assuming. For example, here is how you would update <code>~/.aws/config</code> to assume the role assoicated with the <code>saguaro-cluster</code>.</p> <pre><code>[profile saguaro-cluster]\nmfa_serial=arn:aws:iam::&lt;caktus-account-id&gt;:mfa/&lt;username&gt;\nrole_arn=arn:aws:iam::&lt;saguaro-cluster-account-id&gt;:role/CaktusAccountAccessRole-Admins\nsource_profile=caktus\nregion=us-east-1\n</code></pre> <ol> <li>Assume the Role</li> </ol> <pre><code># Assumption: You have already authenticated by running \"aws-vault exec caktus-mfa\".\n# Let's check\n$ env | grep AWS\nAWS_VAULT=caktus-mfa\n...\n...\n# Let's unset the AWS_VAULT environment variable\n$ unset AWS_VAULT\n# Let's clearn the aws-vault's session\n$ aws-vault clear\nCleared 1 sessions.\n# let's switch to the saguaro-cluster role\n$ aws-vault exec saguaro-cluster\nEnter MFA code for arn:aws:iam::&lt;saguaro-cluster-account-id&gt;:mfa/&lt;username&gt;\n# Ensure that you have access to the AWS Account\n$ aws s3 ls\n&lt;list of s3 buckets within the saguaro-cluster account&gt;\n</code></pre> <ul> <li>If you are switching profiles, make sure to run <code>unset AWS_VAULT</code>, and <code>aws-vault clear</code> before running <code>aws-vault exec &lt;role_profile&gt;</code>.</li> <li> <p>If <code>AWS_VAULT</code> is not set then you can assume whichever mfa-enabled profile you would like.</p> </li> <li> <p>Caktus CI/CD Pipeline</p> </li> </ul> <p>AWS Vault does not replace the need to set <code>AWS_PROFILE</code> when running manual deployments, ansible scripts, or developing locally. Make sure to <code>export AWS_PROFILE</code> when deploying/scripting resources.</p>"},{"location":"getting-started/aws-vault/#recommended-background-reading","title":"Recommended Background Reading","text":"<p>If you would like to have a fuller understanding of what\\'s going on under the hood, I recommended these resources.</p> <p>Resources:  - Kyle Knapp\\'s 2017 AWS Reinvent talk - AWS Knowledge Center: How do I use an MFA token to authenticate access to my AWS resources through the AWS CLI? - Sourcing credentials with an external process</p>"},{"location":"getting-started/dev-containers/","title":"Development Containers","text":"<p>Development containers provide a local environment setup option for Mac and Linux at Caktus. Alternatively, if you'd prefer a more customized experience, you'll likely want to follow the general Developer On-boarding docs instead.</p>"},{"location":"getting-started/dev-containers/#goals","title":"Goals","text":"<p>Development containers will:</p> <ul> <li>Use the same Python/Node/etc. versions as the deployed environment.</li> <li>Install base and development Python/Node/etc. packages automatically without having to use homebrew, pyenv, nvm, etc.</li> <li>Streamline database and media sync from staging environments to ease initial setup.</li> <li>Provide aws-cli and kubectl tools so you can access deployed environments.</li> <li>Allow Git pull, commit, and push from within the container if using VS Code devcontainer.</li> </ul>"},{"location":"getting-started/dev-containers/#prerequisites","title":"Prerequisites","text":"<p>To get started, make sure you have:</p> <ul> <li> <p>Git and SSH keys configured as documented in Generating a new SSH key.</p> </li> <li> <p> Container runtime like Docker Desktop on Mac or Docker Engine on Ubuntu.</p> <ul> <li>BuildKit enabled to support features provided by BuildKit builder toolkit.</li> </ul> <p>Quirks with local filesystem (bind) mounts on Linux </p> <p>Inside a container on Linux, any mounted files/folders will have the exact same permissions as outside the container - including the owner user ID (UID) and group ID (GID). Because of this, your container user will either need to have the same UID or be in a group with the same GID. If your user does not have a UID of 1000 (run <code>id</code> in your terminal to check), then you should specify <code>USER_UID</code> and <code>USER_GID</code> in a <code>.env</code> file at the root of your repo:</p> <pre><code>USER_UID=1001\nUSER_GID=1001\n</code></pre> <p>See Add a non-root user to a container for more information.</p> </li> <li> <p> Caktus AWS account and AWS Command Line Interface (AWS CLI) configured for your development projects.</p> </li> <li> <p>(Optional) Visual Studio Code with the Remote Development extension pack. See Developing inside a Container for additional information.</p> </li> </ul>"},{"location":"getting-started/dev-containers/#project-setup","title":"Project Setup","text":"<p>A project's documentation is the canonical setup documentation. Please refer to your project docs for detailed setup instructions.</p> <p>However, most projects should roughly follow this pattern:</p> <ol> <li>Build and start dev container: Using the VS Code Command Pallete (<code>\u21e7\u2318P</code>), select <code>Dev Containers: Reopen in Container</code>.</li> <li>Install Python and Node requirements: <pre><code>python3 -m venv /code/venv\nmake setup\nnpm install\n</code></pre></li> <li>Setup pre-commit: Insetall pre-commit to enforce a variety of community standards:    <pre><code>pre-commit clean\npre-commit install\n</code></pre></li> <li>Reset local database: Download copy of staging database and restore it locally:    <pre><code>inv staging aws.configure-eks-kubeconfig\ninv staging pod.get-db-dump\ndropdb --if-exists DATABASENAME &amp;&amp; createdb DATABASENAME\npg_restore -Ox -d $DATABASE_URL &lt; *.dump\n</code></pre></li> <li>Reset local media: Download copy of staging media:    <pre><code>mkdir -p /code/media &amp;&amp; sudo chown -R appuser:appuser /code/media\ninv staging aws.sync-media --sync-to local --bucket-path=\"media/\"\n</code></pre></li> <li>Start dev server:: Start the Django development server:    <pre><code>python manage.py runserver 0.0.0.0:8000\n</code></pre></li> <li>Start Node dev server: Start the Node development server in a separate terminal:    <pre><code>npm run dev\n</code></pre></li> </ol>"},{"location":"getting-started/dev-containers/#published-ports","title":"Published ports","text":"<p>Containers are separate environments, so if you want to access a server, service, or other resource inside your container, you will need to either \"forward\" or \"publish\" the port to your host. Where possible, containers will publish ports according to  Development Containers: Port Mappings to avoid collisions. You may temporarily forward a port as a fallback or workaround.</p>"},{"location":"getting-started/dev-containers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/dev-containers/#bad-configuration-option-usekeychain","title":"Bad configuration option: usekeychain","text":"<p>If you're on a Mac, you may see an error like this:</p> <pre><code>/home/appuser/.ssh/config: line 3: Bad configuration option: usekeychain\n/home/appuser/.ssh/config: terminating, 1 bad configuration options\nfatal: Could not read from remote repository.\n</code></pre> <p>This is due to a special config option available on the Mac ssh-agent. To allow the dev container ssh-agent to ignore it, add this line to the top of <code>~/.ssh/config</code>:</p> <pre><code>IgnoreUnknown AddKeysToAgent,UseKeychain\n</code></pre>"},{"location":"getting-started/dev-containers/#an-error-occured-setting-up-the-container","title":"An error occured setting up the container","text":"<p>If you're on a Mac, you may see an error like this:</p> <pre><code>Stop (69 ms): Inspecting container\nStart: Run in container: /bin/sh\nStart: Run in container: uname -m\nStop (91 ms): Run in container: /bin/sh\nShell server terminated (code: 126, signal: null)\nunable to find user appuser: no matching entries in passwd file\nStart: Run in container: cat /etc/passwd\nStdin closed!\nError: An error occurred setting up the container.\n</code></pre> <p>To fix it:</p> <p>While on VSCode press <code>command</code> + <code>shift</code> + <code>P</code> on your keyboard Once the popup displays, select <code>Rebuild and Reopen in Container</code> <code>Press command + shift + P</code> Once the popup displays, select and Rebuild and Reopen in Container</p>"},{"location":"getting-started/dev-containers/#unix-file-permissions-modes-show-in-git-diff","title":"Unix file permissions modes show in <code>git diff</code>","text":"<p>From this Stack Overlow post, git thinks that it can correctly set the executable bit on checked out files, but when it attempts to do so it doesn't work. When it then reads back the status of those files it looks like the executable bit has been deliberately unset.</p> <p>Until we figure out why this occurs, you can tell git to ignore any executable bit changes on the filesystem:</p> <pre><code>git config core.filemode false\n</code></pre>"},{"location":"getting-started/kubernetes/","title":"Kubernetes","text":"<p>The current Caktus Kubernetes version target is v1.29 for projects under Hosting Services.</p>"},{"location":"getting-started/kubernetes/#install-kubectl","title":"Install kubectl","text":"<p>The Kubernetes command-line tool, kubectl, allows you to run commands against Kubernetes clusters. </p> <p>kubectl is installable on a variety of platforms. See Patch Releases for the lastest release versions. Follow the instructions below to install kubectl.</p> <p>Caktus Hosting Services currently recommends this version:</p> <pre><code>export KUBECTL_VERSION=1.29.3\n</code></pre>"},{"location":"getting-started/kubernetes/#apple-silicon-arm","title":"Apple Silicon (ARM)","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/v$KUBECTL_VERSION/bin/darwin/arm64/kubectl\"\nchmod +x ./kubectl\nsudo mv ./kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"getting-started/kubernetes/#apple-intel-x86","title":"Apple Intel (x86)","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/v$KUBECTL_VERSION/bin/darwin/amd64/kubectl\"\nchmod +x ./kubectl\nmv ./kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"getting-started/kubernetes/#linux-x86","title":"Linux (x86)","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/v$KUBECTL_VERSION/bin/linux/amd64/kubectl\"\nchmod +x ./kubectl\nmv ./kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"getting-started/kubernetes/#helm","title":"Helm","text":"<p>Helm is a package manager for Kubernetes and we use various Helm charts at Caktus. To install, follow the instructions below.</p> <p>Caktus Hosting Services currently recommends this version:</p> <pre><code>export HELM_VERSION=3.14.4\n</code></pre> <p>However, you may browse the Helm releases to find a desired version.</p>"},{"location":"getting-started/kubernetes/#apple-silicon-arm_1","title":"Apple Silicon (ARM)","text":"<pre><code>curl -LO \"https://get.helm.sh/helm-v$HELM_VERSION-darwin-arm64.tar.gz\"\ntar -zxf helm*.tar.gz\nmv ./darwin-arm64/helm /usr/local/bin\n</code></pre>"},{"location":"getting-started/kubernetes/#apple-intel-x86_1","title":"Apple Intel (x86)","text":"<pre><code>curl -LO \"https://get.helm.sh/helm-v$HELM_VERSION-darwin-amd64.tar.gz\"\ntar -zxf helm*.tar.gz\nmv ./darwin-amd64/helm /usr/local/bin\n</code></pre>"},{"location":"getting-started/kubernetes/#linux-x86_1","title":"Linux (x86)","text":"<pre><code>curl -LO \"https://get.helm.sh/helm-v$HELM_VERSION-linux-amd64.tar.gz\"\ntar -zxf helm*.tar.gz\nsudo mv ./linux-amd64/helm /usr/local/bin\n</code></pre> <p>Verify it's installed correctly. You should see something like this:</p> <pre><code>\u276f helm version \nversion.BuildInfo{Version:\"v3.8.1\", GitCommit:\"5cb9af4b1b271d11d7a97a71df3ac337dd94ad37\", GitTreeState:\"clean\", GoVersion:\"go1.17.5\"}\n</code></pre>"},{"location":"infrastructure/proxmox/","title":"Caktus Proxmox Server","text":""},{"location":"infrastructure/proxmox/#replacing-a-bad-hard-drive","title":"Replacing a bad hard drive","text":"<p>This server has 4 bays, only 3 active disks. You can use the spare to load a new drive before removing the old one.</p> <ol> <li>Install the new drive.</li> <li>SSH to the server:    <pre><code>ssh root@172.20.1.40\n</code></pre></li> <li>To identify the new disk (e.g., <code>/dev/sdd</code>), run <code>dmesg</code> and look for the \"Attached scsi generic\" message. <code>lsblk</code> (list block devices) will also provide useful summary information.</li> <li>Run a short smartctl test on the device:    <pre><code>smartctl -t short /dev/sdd\n</code></pre>    Look for the test results in a couple minutes with:    <pre><code>smartctl -a /dev/sdd\n</code></pre></li> <li>Identify the disk to be replaced (e.g., from the serial number in emails from Proxmox)</li> <li>Follow the instructions in the Proxmox Admin Guide for Changing a failed bootable drive, for example:    <pre><code>sgdisk /dev/sda -R /dev/sdd\nsgdisk -G /dev/sdd\n</code></pre></li> <li>Identify the new partition to add to the pool:    <pre><code>ls -l /dev/disk/by-id/|grep sdd\n</code></pre></li> <li>Replace the disk:    <pre><code>zpool replace -f rpool /dev/disk/by-id/ata-WDC_WD2003FYYS-02W0B0_WD-WMAY00155507-part3 /dev/disk/by-id/ata-WDC_WD30EFAX-68JH4N1_WD-WXB2DA19JT8Z-part3\n</code></pre></li> <li>Identify the serial number of the disk to be removed (<code>WMAY00155507</code> in the above example), and remove it from the server. Serial numbers are visible through the drive cage on the front of the server.</li> </ol>"},{"location":"infrastructure/hosting-services/backups/","title":"Backups","text":""},{"location":"infrastructure/hosting-services/backups/#cutover-instructions","title":"Cutover Instructions","text":""},{"location":"infrastructure/hosting-services/backups/#start-one-shell-connected-as-the-admin-rds-user","title":"Start one shell connected as the admin RDS user","text":"<p><pre><code>inv pod.debian\napt update &amp;&amp; apt install postgresql-client -y\nexport DATABASE_URL=...\npsql $DATABASE_URL\n</code></pre> NOTE (requires invoke-kubsaea&gt;=0.0.20): If you need a differenct version of debian so that you have the right postgressql-client you can specify it with <code>inv pod.debian --debian-flavor &lt;bullseye:buster:stretch&gt;</code>.</p> <p>Run once replicas are scaled down:</p> <pre><code>DROP DATABASE mywebapp_production;\nCREATE DATABASE mywebapp_production;\n\n-- Connect to recreated DB and create extensions if needed\n\\c mywebapp_production;\nCREATE EXTENSION IF NOT EXISTS postgis;\nCREATE EXTENSION IF NOT EXISTS hstore;\n</code></pre>"},{"location":"infrastructure/hosting-services/backups/#restore-instructions-kubectl","title":"Restore instructions (kubectl)","text":"<pre><code># scale down (to release DB connections) and drop DB above\nkubectl -n mywebapp-production scale deployment/app --replicas=0\n# scale back up\nkubectl -n mywebapp-production scale deployment/app --replicas=2\n# restore DB\ninv production pod.restore-db-from-dump --db-var=\"DATABASE_URL\" --filename=mywebapp-archive.dump\n</code></pre> <p>NOTE:</p> <p>If your stack has celery installed then you will need to scale those down as well to free resources:</p>"},{"location":"infrastructure/hosting-services/backups/#restore-instructions-invoke-kubesae","title":"Restore instructions (invoke-kubesae)","text":"<p>As of version <code>0.0.21</code> invoke-kubesae, has a utility command <code>utils.scale-app</code> to help with this.</p>"},{"location":"infrastructure/hosting-services/backups/#usage-examples","title":"Usage Examples","text":"<pre><code> &gt; inv staging utils.scale-app --down  # Scales the containers to 0.\n&gt; inv staging utils.scale-app --down --celery  # Scales the containers, celery-worker, and celery-beat to 0.\n&gt; inv staging utils.scale-app  # Scales the containers to 2.\n&gt; inv staging utils.scale-app --celery  # Scales the containers to 2, and celery-worker/celery-beat to 1.\n&gt; inv staging utils.scale-app --container-count 4  # Scales the containers to 4.\n&gt; inv staging utils.scale-app --container-count 4 --celery  # Scales the containers to 4, and celery-worker/celery-beat to 1.\n</code></pre>"},{"location":"infrastructure/hosting-services/backups/#post-restore-tasks","title":"Post-restore tasks","text":"<ol> <li>Wagtail:<ol> <li>Update <code>Site</code> object with correct domain.</li> </ol> </li> <li> <p>Manually run migrations:</p> <p><pre><code>kubectl -n mywebapp-production exec -it deploy/app -- python manage.py migrate\n</code></pre> 3. Manually create new superuser:</p> <pre><code>kubectl -n mywebapp-production exec -it deploy/app -- python manage.py createsuperuser\n</code></pre> </li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/","title":"Disaster Recovery","text":"<p>Caktus provides managed hosting services for many projects, which include periodic backups and application recovery. For example, restoring a deployed environment after (1) a hardware or cloud environment failure or (2) a user or application bug accidentally deletes data. Here we document our strategy and approach for disaster recovery.</p>"},{"location":"infrastructure/hosting-services/disaster-recovery/#our-goals","title":"Our goals","text":"<ul> <li>Redundancy: We back up or replicate data (database, uploaded files, etc.) to a separate location or region from the deployed environment. For example, if the site is deployed to <code>us-east-1</code>, backup data to <code>us-east-2</code>.</li> <li>Recoverability: We perform periodic backup verifications to ensure the integrity of our backups by restoring them to a freshly deployed environment.</li> <li>Not Staging: Backups are restored to a dedicated environment to not impact active development on staging and production.</li> </ul>"},{"location":"infrastructure/hosting-services/disaster-recovery/#prerequisites","title":"Prerequisites","text":"<p>To get started, make sure you have:</p> <ul> <li> Caktus AWS account and AWS Command Line Interface (AWS CLI) configured for your development projects.</li> </ul>"},{"location":"infrastructure/hosting-services/disaster-recovery/#backup-verification-workflow","title":"Backup verification workflow","text":"<p>A project's documentation contains the canonical backup instructions. Please refer to your project docs for detailed setup instructions.</p> <p>However, most projects should roughly follow this pattern:</p> <ol> <li>Obtain latest production backup archive:    <pre><code>inv utils.get-db-backup\n</code></pre></li> <li>Restore database archive into disaster recovery environment:    <pre><code>inv dr deploy.db-restore --filename=&lt;FILENAME&gt;\n</code></pre></li> <li>Deploy a recent application image to the disaster recovery environment:    <pre><code># Find current deployed tag, where &lt;NAMESPACE&gt; is the production namespace.\nkubectl -n &lt;NAMESPACE&gt; get deployments -o wide\n# Deploy (&lt;TAG&gt; is at the end of the app image string after the colon.)\ninv dr deploy --tag=&lt;TAG&gt;\n</code></pre></li> <li>Visit deployed site in your browser, log in, update Site object, and perform basic smoke tests:<ul> <li>Create new pages</li> <li>Upload images</li> </ul> </li> <li>Once complete, turn off disaster recovery environment:    <pre><code>kubectl -n &lt;NAMESPACE&gt; scale deployments --replicas=0 --all\n</code></pre></li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/#initial-setup","title":"Initial setup","text":""},{"location":"infrastructure/hosting-services/disaster-recovery/#dr-provisioning","title":"DR provisioning","text":""},{"location":"infrastructure/hosting-services/disaster-recovery/#aws-replicated-object-bucket","title":"AWS - Replicated object bucket","text":"<ol> <li>Create a new bucket in the AWS S3 console with:<ul> <li>Bucket name: <code>PROJECTNAME</code>-dr-assets</li> <li>AWS Region: A region other than the source bucket for Cross-Region Replication</li> <li>Object Ownership: Same as the source bucket (most likely ACLs enabled)</li> <li>Block Public Access settings for this bucket: Same as the source bucket</li> <li>Bucket Versioning: Same as the source bucket</li> <li>Default encryption: Same as the source bucket</li> </ul> </li> <li>In the AWS S3 console, navigate to the source bucket, click the Management tab, and then select Create replication rule: <ul> <li>Replication rule name: DR Replication</li> <li>Destination: Select the bucket you created above</li> <li>IAM Role: Select Create new role</li> </ul> </li> <li>After clicking Save, choose to replicate existing objects on the modal window:<ul> <li>Completion report: s3://<code>PROJECTNAME</code>-dr-assets/replication-reports</li> <li>Permissions: Choose from existing IAM roles and Create a new role</li> </ul> </li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/#add-dns-record","title":"Add DNS Record","text":"<p>Create a CNAME record, for example dr.<code>PROJECTNAME</code>.com and point it to the cluster Load Balancer DNS name or alias. </p>"},{"location":"infrastructure/hosting-services/disaster-recovery/#update-iam-assets-management-policy","title":"Update IAM assets management policy","text":"<ol> <li>Go to IAM &gt; Roles &gt; and search for the <code>ContainerInstanceRole</code></li> <li>Edit the AssetsManagementPolicy to include the newly-created DR bucket     <pre><code>{\n[\n...\n{\n\"Action\": [\n\"s3:ListBucket\"\n],\n\"Resource\": \"arn:aws:s3:::BUCKETNAME\",\n\"Effect\": \"Allow\"\n},\n{\n\"Action\": [\n\"s3:*\"\n],\n\"Resource\": \"arn:aws:s3:::BUCKETNAME/*\",\n\"Effect\": \"Allow\"\n}\n]\n}\n</code></pre></li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/#create-dr-ansible-configuration","title":"Create <code>dr</code> Ansible configuration","text":"<ol> <li>Create <code>group_vars/staging_shared.yaml</code> with common configuration between <code>staging</code> and <code>dr</code></li> <li>Create <code>host_vars/dr.yaml</code> with domain name, basic auth password, etc.</li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/#database-backups","title":"Database backups","text":""},{"location":"infrastructure/hosting-services/disaster-recovery/#aws-hosting-services-bucket","title":"AWS - Hosting Services bucket","text":"<p>This private bucket will store database archives.</p> <ol> <li>Create a new bucket in the AWS S3 console with:<ul> <li>Bucket name: <code>PROJECTNAME</code>-hosting-services</li> <li>AWS Region: A region other than the source bucket for Cross-Region Replication</li> <li>Object Ownership: ACLs disabled</li> <li>Block Public Access settings for this bucket: Block all public access</li> <li>Bucket Versioning: Enable</li> <li>Default encryption: Enable</li> </ul> </li> </ol>"},{"location":"infrastructure/hosting-services/disaster-recovery/#backup-user","title":"Backup user","text":"<ol> <li>Create a new user in the AWS IAM console with:<ul> <li>User name: <code>PROJECTNAME</code>-backups</li> <li>AWS credential type: Access key - Programmatic access</li> <li>Permissions: Skip for now</li> <li>Tags: Skip for now</li> <li>Download and save the access credentials CSV file.</li> </ul> </li> <li>Click on the newly created user in the AWS IAM console and click Add inline policy:     <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"ListObjectsInBucket\",\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::PROJECTNAME-hosting-services\"\n]\n},\n{\n\"Sid\": \"ObjectActions\",\n\"Effect\": \"Allow\",\n\"Action\": \"s3:PutObject\",\n\"Resource\": [\n\"arn:aws:s3:::PROJECTNAME-hosting-services/*\"\n]\n}\n]\n}\n</code></pre></li> </ol>"},{"location":"infrastructure/kubernetes/upgrades/","title":"Kubernetes Upgrades","text":"<p>Caktus routinely performs Kubernetes and related service upgrades as part of our hosting services.</p>"},{"location":"infrastructure/kubernetes/upgrades/#hotfix-branch","title":"Hotfix branch","text":"<p>Upgrades are rolled out to production environments, so create a hotfix branch:</p> <pre><code>git checkout main\ngit pull\ngit checkout -B k8s-upgrades\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#ingress-controller-and-cert-manager","title":"Ingress controller and cert-manager","text":""},{"location":"infrastructure/kubernetes/upgrades/#pin-to-latest-versions","title":"Pin to latest versions","text":"<p>Update <code>k8s_ingress_nginx_chart_version</code> and <code>k8s_cert_manager_chart_version</code> to the target versions, typically in <code>deploy/group_vars/k8s.yaml</code>:</p> <pre><code>k8s_ingress_nginx_chart_version: \"4.0.19\"\nk8s_cert_manager_chart_version: \"v1.7.2\"\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#deploy-the-upgrades","title":"Deploy the upgrades","text":"<pre><code># using kubesae\ninv deploy.install deploy.playbook deploy-cluster.yml\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#troubleshooting","title":"Troubleshooting","text":"<p>If any Ansible tasks fail to run, check for a failed status of the Helm charts in the respective namespaces:</p> <pre><code>helm -n ingress-nginx list\nhelm -n cert-manager list\n</code></pre> <p>Rollback and re-deploy as needed. For example, cert-manager:</p> <pre><code>helm -n cert-manager rollback cert-manager\ninv deploy.install deploy.playbook deploy-cluster.yml\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#re-deploy-app","title":"Re-deploy app","text":"<p>Find environment namespaces:</p> <pre><code>kubectl get ns\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#staging","title":"Staging","text":"<p>Find deployed tag:</p> <pre><code>kubectl -n trafficstops-staging get deploy/app -o yaml | grep image:\n</code></pre> <p>Re-deploy:</p> <pre><code>inv [staging/production] deploy --tag=&lt;insert tag here&gt;\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#site-is-up","title":"Site is up","text":"<p>Verify that the site is up by visiting it on your browser.</p>"},{"location":"infrastructure/kubernetes/upgrades/#production","title":"Production","text":"<p>Repeate these steps for the other namespace(staging/production).</p>"},{"location":"infrastructure/kubernetes/upgrades/#hosting-services","title":"Hosting Services","text":"<p>This section manages database backups, monitoring, and log aggregation.</p>"},{"location":"infrastructure/kubernetes/upgrades/#update-galaxy-requirements","title":"Update Galaxy requirements","text":"<p>Update caktus.k8s-hosting-services to the latest version in <code>deploy/requirements.yml</code>:</p> <pre><code>- src: https://github.com/caktus/ansible-role-k8s-hosting-services\nname: caktus.k8s-hosting-services\nversion: v0.7.0\n</code></pre> <p>Warning</p> <p>Make sure the PostgreSQL client version matches the project's database cluster version. Projects should set k8s_hosting_services_image_tag accordingly to use an image tag with the corresponding PostgreSQL version.</p>"},{"location":"infrastructure/kubernetes/upgrades/#update-chart-versions","title":"Update chart versions","text":"<p>Update the hosting services chart versions to the target versions, typically in <code>deploy/group_vars/k8s.yaml</code>:</p> <pre><code># https://github.com/newrelic/helm-charts/releases\nk8s_newrelic_chart_version: \"4.6.2\"\n# https://hub.docker.com/r/gliderlabs/logspout/tags\nk8s_papertrail_logspout_image_tag: v3.2.14\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#deploy","title":"Deploy","text":"<p>Run the <code>deploy-hosting-services.yml</code> to deploy the latest hosting services:</p> <pre><code>inv deploy.install deploy.playbook deploy-hosting-services.yml\n</code></pre>"},{"location":"infrastructure/kubernetes/upgrades/#commandline-updates-for-aws-eks","title":"Commandline updates for AWS EKS","text":"<p>This command updates an EKS cluster <pre><code>aws eks update-cluster-version --region &lt;AWS Region&gt; --name &lt;cluster name&gt; --kubernetes-version &lt;K8s version to update to&gt;\n</code></pre></p> <p>This command uses the update-id from the update-cluster-version command to list the status of the upgrade  <pre><code>aws eks describe-update --region &lt;AWS Region&gt; --name &lt;cluster name&gt; --update-id &lt;update-ID from update command&gt;  | grep \"status\"\n</code></pre></p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/","title":"Account Configuration","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#configure-aws","title":"Configure AWS","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#setting-up-a-client-sub-account","title":"Setting up a Client sub account","text":"<p>If a client needs to have a sub account created for us to use with our assume roles, follow these instructions.</p> <p>First create the sub-account from the organizations root account</p> <p>Once that is done they will need to log in and do some more work. It is not obvious how to sign in to the  sub-account after they are done with creating it.  Follow these instructions</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#todo-instructions-on-how-to-configure-the-sub-account-for-the-assumerole","title":"TODO: instructions on how to configure the sub-account for the AssumeRole","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#configure-local-project","title":"Configure Local project","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#add-configured-account-to-aws-configs","title":"Add Configured Account to AWS Configs","text":"<p>Once the sub-account and AssumeRole have been configured set up your local AWS_PROFILE</p> <p>Currently, we keep information about the account in two places <code>~/.aws/config</code> and <code>~/.aws/credentials</code>.</p> <p><code>config</code> is where the profile name, and the account region are defined. <code>credentials</code> is where we assign the AssumeRole information and link that with caktus IAM credentials.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#config","title":"Config","text":"<p>Edit the config file, and add a section for the aws account, usually this is some form of the project name.</p> <pre><code>[profile &lt;project_name&gt;]\nregion = &lt;project_region&gt;\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/001_account/#credentials","title":"Credentials","text":"<pre><code>[&lt;profile_name_from_config&gt;]\nrole_arn = arn:aws:iam::&lt;DIGITS&gt;:role/CaktusAccountAccessRole-Admins\nsource_profile = caktus\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/002_encryption/","title":"Encryption configuration","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/002_encryption/#encryption-by-default","title":"Encryption by default","text":"<p>Configure your AWS account to enforce the encryption of new EBS volumes and snapshots. A few notes:</p> <ul> <li>You can launch an instance only if the instance type supports EBS encryption when you enable encryption by default.</li> <li>Encryption by default is a region-specific setting.</li> </ul> <p>Follow the Encryption by default instructions or you can use the AWS CLI. For example:</p> <pre><code>aws --region us-west-1 ec2 enable-ebs-encryption-by-default\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/003_vault_secret/","title":"Configure Secrets","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/003_vault_secret/#on-aws","title":"On AWS","text":"<ol> <li>From the AWS console navigate to the <code>AWS secrets manager</code></li> <li>Click <code>Store a new secret</code></li> <li>Select <code>Other type of secret</code></li> <li>Select <code>Plaintext</code></li> <li>Remove the dictionary.</li> <li>Generate a secret key from the command line <code>pwgen -n 64</code></li> <li>Copy one of the keys into the plaintext input. Ensure that the key is the only string present</li> <li>Ensure that <code>Encryption key</code> has <code>aws/secretsmanager</code> selected</li> <li>Click <code>Next</code></li> <li>Give your secret a name. Convention is <code>&lt;projectname&gt;-ansible-vault-secret</code></li> <li>Click <code>Next</code></li> <li>Click <code>Next</code> again.</li> </ol>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/003_vault_secret/#local","title":"Local","text":"<p>In <code>deploy/echo-vault-pass.sh</code> add the secret name to the <code>export SECRET_ID</code> line.</p> <pre><code>8 export SECRET_ID=\"&lt;projectname&gt;-ansible-vault-secret\"\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/004_database/","title":"Database configuration","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/004_database/#postgresql-rds","title":"PostgreSQL RDS","text":"<p>Choose the latest version of PostgreSQL RDS here. You can also run:</p> <pre><code>aws rds describe-db-engine-versions --default-only --engine postgres\n</code></pre> <p>Pick a version of postgres you want for the project.</p> <p>Newer versions of postgres may not be configured in Caktus AWS Web Stacks.</p> <p>Check here to see if  the version you are targeting is listed. If it is not, open a PR to have it added.</p> <p>You will add your selected version of Postgres to the <code>DatabaseParameterGroupFamily</code> variable found in the WebStacks section of the <code>deploy/group_vars/all.yaml</code> file.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/004_database/#create-postgresql-databases","title":"\ud83d\uddc4\ufe0f Create PostgreSQL databases","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/004_database/#temporary-pod","title":"Temporary pod:","text":"<p>Launch a temporary Debian pod within the cluster</p> <pre><code>inv pod.debian\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/004_database/#install-postgres-client","title":"Install postgres client","text":"<p>The temporary pods don't have much in them, so you will need to install <code>postgresql-client</code> and connect to the RDS PostgreSQL cluster as the admin user. The Admin </p> <pre><code>apt update &amp;&amp; apt install postgresql-client -y\nexport DATABASE_URL=...\npsql $DATABASE_URL\n</code></pre> <ol> <li>Create the environment's role::</li> </ol> <pre><code>CREATE ROLE &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt; WITH LOGIN NOSUPERUSER INHERIT CREATEDB NOCREATEROLE NOREPLICATION PASSWORD '&lt;password1&gt;';\n</code></pre> <ol> <li>Create environment-specific databases, e.g.::</li> </ol> <pre><code>CREATE DATABASE &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt;;\nGRANT CONNECT ON DATABASE &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt; TO &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt;;\nGRANT ALL PRIVILEGES ON DATABASE &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt; TO &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt;;\n</code></pre> <p>If your project has postgres extensions that need to be added, you will need to do this at the same time.</p> <p>For example to add the CITEXT extension you would also run on each database in use for the cluster ('staging', 'production'):</p> <pre><code>\\connect &lt;&lt;PROJECT_NAME&gt;&gt;_&lt;&lt;ENVIRONMENT&gt;&gt;;\nCREATE EXTENSION IF NOT EXISTS citext;\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/","title":"Cloudformation Setup","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#get-the-template","title":"Get the template","text":"<p>From the Caktus AWS WebStacks repository find the  template that suits your needs. For the vast majority of cases you will want to use  eks-nat.yaml. After downloading  it is a good idea to set the version (e.g. <code>eks-nat-2.1.2.yaml</code>). You can grab that from the latest tag.</p> <p>Copy the file into your project's <code>deploy/stack</code> folder.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#configure-the-ansible-variables","title":"Configure the ansible variables","text":"<p>The variables for your stack are often found in the <code>deploy/group_vars/all.yaml</code>.</p> <p>EXAMPLE:</p> <pre><code># ----------------------------------------------------------------------------\n# AWS Web Stacks: Configuration variables to be used by the\n#                 caktus/aws-web-stacks role\n# ----------------------------------------------------------------------------\n\ncloudformation_stack_profile: '{{ aws_profile }}'\ncloudformation_stack_region: '{{ aws_region }}'\ncloudformation_stack_name: '{{ app_name }}-{{ env_name }}-stack'\ncloudformation_stack_template_local_path: '{{ playbook_dir + \"/stack/eks-nat-2.1.2.yaml\" }}'\ncloudformation_stack_template_bucket: 'aws-web-stacks-{{ app_name }}'\ncloudformation_stack_template_bucket_path: 'templates/{{ env_name }}/{{ cloudformation_stack_name }}.yml'\ncloudformation_stack_create_changeset: true\ncloudformation_stack_template_parameters:\nPrimaryAZ: \"{{ aws_region }}a\"\nSecondaryAZ: \"{{ aws_region }}b\"\nDesiredScale: 2\nMaxScale: 2\nUseAES256Encryption: \"true\"\nCustomerManagedCmkArn: \"\"\nContainerInstanceType: t3a.medium\nContainerVolumeSize: 30\nDatabaseClass: db.t3.small\nDatabaseEngineVersion: \"14\"\nDatabaseParameterGroupFamily: postgres14\nDatabaseMultiAZ: \"true\"\nDatabaseUser: \"{{ admin_database_user|default(app_name) }}\"\nDatabasePassword: \"{{ admin_database_password }}\"\nDatabaseName: \"{{ admin_database_name|default(app_name) }}\"\nDomainName: \"{{ app_name }}.\" ## What should this be\nDomainNameAlternates: \"\"\nAssetsUseCloudFront: \"false\"\n# Bastion host\nBastionKeyName: &lt;some-pre-existing-key-pair&gt;\n</code></pre> <p>Note: You may ask yourself, what is going on with that <code>BastionKeyName</code> variable, I don't need a bastion server. That may be true but head to the appendix to find out why it is needed. The Trouble With Bastion</p> <p>Note: If you need to encrypt cluster secrets follow head on down to Envelope encryption</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#add-ansible-role-to-the-deployment","title":"Add ansible role to the deployment","text":"<p>To use WebStacks we need to install Caktus AWS Web Stacks Role into the project.</p> <p>Add the following to <code>deploy/requirements.yaml</code>:</p> <pre><code>- src: https://github.com/caktus/ansible-role-aws-web-stacks\nname: caktus.aws-web-stacks\nversion: ''\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#install-the-role","title":"Install the role","text":"<pre><code>$ ansible-galaxy install -f -r deploy/requirements.yaml\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#run-the-cloudformation-stack-playbook","title":"Run the CloudFormation Stack Playbook","text":"<pre><code>$ ansible-playbook deploy/deploy-cf-stack.yaml\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#configure-services","title":"Configure Services","text":"<p>After cloudformation has run, it will have created a bunch of services within the AWS account.</p> <ol> <li>An EKS cluster.</li> <li>An ECR repository.</li> <li>An RDS database.</li> </ol> <p>the ansible process will print into the terminal a list of resources that you will use to populate variables in the <code>deploy</code> files.</p> <pre><code>TASK [caktus.aws-web-stacks : print cf_stack_outputs] ****************************************************************************************************************************************************************************************************\nok: [aws.amazon.com] =&gt; cloudformation_stack_result.stack_outputs:\n    AssetsBucketDomainName: &lt;VALUE&gt;\n    ClusterEndpoint: https://&lt;VALUE&gt;.eks.amazonaws.com\n    DatabaseAddress: &lt;VALUE&gt;.rds.amazonaws.com\n    DatabasePort: '5432'\nDatabaseURL: postgres://&lt;VALUE&gt;.rds.amazonaws.com:5432/&lt;APP_NAME&gt;\n    PrivateAssetsBucketDomainName: &lt;VALUE&gt;-privateassetsbucket-y1hs1zsetsnc.s3.amazonaws.com\n    RepositoryURL: &lt;VALUE&gt;-us-east-2.amazonaws.com/&lt;VALUE&gt;-applicationrepository-wh5tljkspmgv\n</code></pre> <p>Now you can take this information and Configure your services</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#appendix","title":"Appendix","text":""},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#the-trouble-with-bastion","title":"The trouble with Bastion","text":"<p>Currently, there is a known limitation with WebStacks and Bastion Even if your project does not need a Bastion server, the cloudformation process will fail because of a Type validation check. So a workaround is to create a key pair in EC2, and use the keyname in  the <code>BastionKeyName</code> variable.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#create-a-key-pair","title":"Create a Key Pair","text":"<p>NOTE: Make sure you are in the same region the cluster will be created in.</p> <ol> <li>Navigate to EC2 in the AWS console.</li> <li>Under <code>Network and Security</code> menu on the left select <code>Key Pairs</code></li> <li>Click the <code>Create Pair</code> button in the top right.</li> <li>Enter the Key name you wish to use.</li> <li>Select <code>ED25519</code> type.</li> <li>Click <code>Create Key Pair</code></li> </ol>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/005_cloudformation/#envelope-encryption-of-cluster-secrets","title":"Envelope Encryption of Cluster Secrets","text":"<p>One of the considerations for the security of the cluster is whether you want to encrypt the Cluster secrets. The decision-making process for this is well beyond the scope of this doc, but if you do, you will need to add a  <code>Customer Managed Key</code> to the account.</p> <ol> <li>In the AWS console, navigate to <code>Key Management Service (KMS)</code>.</li> <li>In the top right click <code>Add a Key</code>.</li> <li>Leave <code>Symmetric</code> checked and click <code>Next</code>.</li> <li>Add an <code>Alias</code> for the CMK, and click <code>Next</code>.</li> <li>For <code>Key administrators</code> check <code>CaktusAccountAccessRole-Admins</code> and click <code>Next</code>.</li> <li>For <code>Define key usage permissions</code> check <code>AWSServiceRoleForAmazonEKS</code> and <code>AWSServiceRoleForRDS</code></li> <li>Click <code>Next</code>, and <code>Next</code></li> </ol> <p>Now the key will be created, and you will need to copy the <code>arn</code> for the key into the <code>CustomerManagedCmkArn</code> entry.</p> <ol> <li>Click into the detail for key you created.</li> <li>Copy the ARN from the <code>General Information</code> section.</li> </ol>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/006_service_configuration/","title":"Configure Services","text":"<p>The configuration of services for your deployment will occur almost entirely in the <code>deploy/group_vars/all.yaml</code> file.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/006_service_configuration/#allyaml-global-configuration","title":"(all.yaml) Global configuration","text":"<pre><code># ----------------------------------------------------------------------------\n# Global: CloudFormation stack outputs. See all.yml for stack parameters.\n# ----------------------------------------------------------------------------\n\nClusterEndpoint: &lt;ClusterEndpoint from CloudFormation output&gt;\nDatabaseAddress: &lt;DatabaseAddress from CloudFormation output&gt;  # The connection endpoint for the database. -\nRepositoryURL: &lt;DIGITS&gt;.dkr.ecr.&lt;ACCOUNT_REGION&gt;.amazonaws.com  # The docker repository URL\n</code></pre> <p>The output for <code>RepositoryURL</code> is in two parts the first part is up to the first <code>/</code>. Copy that into <code>RepositoryURL</code>. The second part goes in <code>k8s_container_image</code> under App Pod Configuration</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/006_service_configuration/#app-pod-configuration","title":"App Pod Configuration","text":"<pre><code># ----------------------------------------------------------------------------\n# App Pod Configuration\n# ----------------------------------------------------------------------------\n...Defaults\n\nk8s_container_image: \"{{ RepositoryURL }}/&lt;SECOND_PART_OF_REPOSITORY_URL&gt;\"\n\n# Sentry\n\n# Papertrail\nk8s_papertrail_logspout_destination: &lt;ENCRYPTED_PAPERTRAIL_ENDPOINT&gt;\nk8s_papertrail_logspout_memory_limit: 128Mi\n\n...End Defaults\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/006_service_configuration/#k8syaml-shared-environment-variables","title":"(k8s.yaml) Shared Environment Variables","text":"<p>Shared variables is a section in the <code>k8s.yaml</code> file where you can configure some items that would most likely be shared between all of your environments.</p> <p>Variables in this section are also prefixed with <code>env_</code>, this usually indicates that they will be  used by Django or something else in the app.</p> <pre><code># ----------------------------------------------------------------------------\n# Shared Environment Variables\n# ----------------------------------------------------------------------------\nenv_database_url: \"postgres://{{ django_app_name }}_{{ env_name }}:{{ database_password }}@{{ DatabaseAddress }}:5432/{{ django_app_name }}_{{ env_name }}\"\nenv_django_settings: \"{{ django_app_name }}.settings.deploy\"\nenv_cache_host: memcached:11211\nenv_default_file_storage: \"DjangoFileSystem\"\n\nenv_media_storage_bucket_name: \"\"\nenv_aws_default_acl: public-read\nenv_media_location: \"{{ env_name }}/media/\"\n\n# Email\nenv_email_host: env_email_host_user: env_email_host_password: env_default_from_email: env_default_from_email# New Relic APM: Caktus Free Account\nenv_new_relic_app_name: \"{{ k8s_namespace }}\"\nenv_new_relic_license_key: # Sentry\nenv_sentry_dsn: &lt;UNENCRYPTED_SENTRY_DSN&gt;\n</code></pre>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/006_service_configuration/#papertrail","title":"Papertrail","text":"<p>To set up a system for your project in sentry you will need access to Caktus' papertrail account.</p>"},{"location":"infrastructure/kubernetes/Kubernetes-AWS/007_cd/","title":"Continuous Deployment","text":"<p>Set <code>k8s_ci_repository_arn</code> and <code>k8s_ci_vault_password_arn</code> in <code>deploy/host_vars/k8s.yml</code> to the specific environment's AWS ARNs:</p> <pre><code># file: group_vars/k8s.yaml\n# Continuous integration:\nk8s_ci_aws_profile: \"{{ aws_profile }}\"\nk8s_ci_username: \"{{ app_name }}-ci-user\"\n# aws ecr describe-repositories | grep Arn\nk8s_ci_repository_arn: \"\"\n# aws secretsmanager list-secrets\nk8s_ci_vault_password_arn: \"\"\n</code></pre> <p>Run this playbook:</p> <pre><code># file: deploy-cd-iam-user.yaml\n- hosts: k8s\ngather_facts: false\ntasks:\n- name: configure CD IAM user\nimport_role:\nname: caktus.django-k8s\ntasks_from: aws_ci\n</code></pre> <p>Example:</p> <pre><code>inv staging deploy.playbook -n deploy-cd-iam-user.yaml\n</code></pre> <p>Access <code>\"{{ app_name }}-ci-user\"</code> in the IAM section of AWS console and generate accesses keys for use with GitHub actions.</p>"},{"location":"policies/security-policy/","title":"Security Policy","text":"<p>Note</p> <p>Accessing most of the links below require being on the Caktus Group networks.</p> <p>At Caktus we strive to adhere to community security best practices. We recognize the importance of the confidential information shared with us by clients regularly and give it the respect and care needed when storing and transferring confidential information.</p> <p>Caktus is committed to protecting its employees, clients, and the company from illegal or damaging actions by individuals, either knowingly or unknowingly. Effective security is a team effort involving the participation and support of every Caktus employee and affiliate who deals with information and/or information systems.</p>"},{"location":"policies/security-policy/#acceptance-and-training","title":"Acceptance and Training","text":"<ol> <li>This policy applies to employees, contractors, consultants, interns, and other workers at Caktus.</li> <li>This policy applies to all equipment that is owned or leased by Caktus and all equipment owned or leased by contractors and consultants used while performing work for Caktus.</li> <li>It is the responsibility of the individual to know these guidelines, and to conduct their activities accordingly.</li> <li>Employees, contractors, consultants, and interns must complete training assigned in KnowBe4 (https://training.knowbe4.com/ui/dashboard/)</li> <li>High Security Projects<ol> <li>Employees and Contractors must read and accept the Security Policy in the KnowBe4 console (https://training.knowbe4.com/ui/training/policies) acknowledging understanding of this policy.</li> <li>Employees and Contractors may need to undergo client-specific security trainings.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#security-incident-response","title":"Security Incident Response","text":"<ol> <li>General ongoing security related concerns and immediate security incidents should be shared via email with security@caktusgroup.com as soon as they have been identified. These may include security incidents and concerns on Caktus maintained projects, software applications and libraries used at Caktus, third party services we utilize, and the Caktus office space.</li> <li>Project Security Incidents<ol> <li>In case of a security incident on a Caktus project, the Lead Developer is responsible for leading the security Incident Response with input from Tech Support, third parties, and other relevant Caktii.</li> <li>A Security Incident Response document will be created and shared with the client via the Project Manager within 48 hours of the incident and once the initial assessment has been made.</li> <li>This document will document all compromises, what data may have been compromised, what steps were taken, and are ongoing to remedy the situation.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#physical-facilities-security","title":"Physical Facilities Security","text":"<ol> <li>Access Control and Security System<ol> <li>Caktus\u2019 office space is secured by both an Access Control and Security System.</li> <li>Access to the property requires a valid key card at all times. Only Caktus employees, contractors who regularly work on-site, and janitorial services are provided key cards.</li> <li>The Security System is armed at night between 10p-6a and is triggered by glass break, motion, and door contacts throughout the office.</li> </ol> </li> <li>Keys<ol> <li>All full-time employees are given keys to a locked cabinet for storing workstations and shared electronics. The cabinet must always remain locked. If utilized, you must re-lock it immediately after each use.</li> <li>File cabinets are secured by key and accessible only by the Operations Team.</li> <li>The server closet is secured by key and only Tech Support, Operations Team, and Marketing Team are provided access.</li> </ol> </li> <li>Visitors<ol> <li>Clients and other visitors to the secured second floor work area who are meeting on premises are to be accompanied by a Caktus employee at all times.</li> <li>Visitors to local events are only allowed access to the Caktus Tech Space on the 1st floor. There is no private information stored on this floor. There are access controlled locks between the first floor and second floor at all times.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#clean-workstation","title":"Clean Workstation","text":"<ol> <li>Employees are required to ensure that all sensitive/confidential information in hardcopy or electronic form is secure in their work area at the end of the day and when they are expected to be gone for an extended period.</li> <li>Any sensitive/confidential information must be removed from workspace and locked in a cabinet when the desk is unoccupied and at the end of the work day. </li> <li>Passwords may not be left on sticky notes posted on or under a computer, nor may they be left written down in an accessible location. </li> <li>Printouts containing sensitive/confidential information should be immediately removed from the printer. </li> <li>Upon disposal of sensitive/confidential documents, they should be shredded using the shredder at the reception desk in the main work area.</li> <li>Whiteboards containing sensitive/confidential information should be erased once the meeting or work session in which they were created in finished.</li> </ol>"},{"location":"policies/security-policy/#network-and-wifi","title":"Network and WiFi","text":"<ol> <li>The Caktus office network is behind a firewall.</li> <li>WiFi access is partitioned into Caktus and Guest networks.<ol> <li>Credentials to access the primary Caktus network are only provided to employees and on-site contractors.</li> <li>The Caktus-Guest network is password protected and is partitioned safely from the primary Caktus network.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#workstations","title":"Workstations","text":"<ol> <li>Caktus workstations (laptops) are intended for use exclusively on work-related projects in order to limit the chance of infection of the computer with malware. However, you may work on personal development projects that use Caktus-related technologies (e.g. Django projects) on your Caktus workstation. This applies to professional development activities like attending a conference.</li> <li>It is understood that in the course of completing one\u2019s day-to-day job, especially as a software developer, it is important to have administrative access to control your own workstation to download and run software from the Internet. Please use common sense and evaluate each third-party piece of software carefully before installing it.</li> <li>Security<ol> <li>Workstations must be screen-locked when workspace is unoccupied.</li> <li>Workstations must be kept in a secure, locked cabinet when not in the presence of their user. </li> <li>Encryption will always be enabled for confidential data in transit through SSH and HTTPS connections.</li> <li>All workstations are provisioned with the following defaults and services (and they should not be changed):<ol> <li>Disabled SSH password authentication</li> <li>Latest supported Operating Systems and automatic security updates</li> <li>All workstations have their data secured at rest using GPG encrypted files, and LUKS &amp; FileVault whole disk encryption.</li> <li>Tech Support SSH remote access</li> </ol> </li> <li>Workstations assigned to High Security Projects are provisioned with the following defaults and services (and they should not be changed):<ol> <li>Firewall</li> <li>Antivirus software</li> <li>fail2ban</li> </ol> </li> </ol> </li> <li>Maintenance and Backups<ol> <li>Regular maintenance of workstations is performed, including regular security updates using automated tools.</li> <li>Backups and Logs<ol> <li>Backups are stored on a secure and updated FreeNAS computer stored in a locked server closet.</li> <li>Logs are stored centrally for each computer including security related daemon logs &amp; login details.</li> <li>All backups and logs are stored for a minimum of 12 months.</li> </ol> </li> </ol> </li> </ol>"},{"location":"policies/security-policy/#personal-computers-phones","title":"Personal Computers &amp; Phones","text":"<ol> <li>It is required that employees restrict access to Caktus\u2019 computing infrastructure from their personal workstations and communication devices. Accessing client-owned services from a personal device is prohibited unless otherwise approved by the Security Team.</li> <li>For convenience, you may access Caktus services from personal devices, but please restrict access to the minimum set of services required to perform your duties.<ol> <li>You are required to enable the following security precautions on your mobile device:<ol> <li>Configure a lock screen with a 5 minute timeout on your devices</li> <li>Enable \u201cEncrypt Device\u201d on Android devices</li> <li>Keep OS up to date with the latest security updates available</li> </ol> </li> <li>We recommend you enable the following security precautions on your mobile device:<ol> <li>Android: Find my Phone</li> <li>iPhone: Find my iPhone (so you can use https://www.icloud.com/#find)</li> </ol> </li> </ol> </li> <li>For services not on your personal mobile device, like your laptop, only access Caktus services via a separate incognito browser session.</li> <li>All others services should only be accessed using your Caktus workstation.</li> </ol>"},{"location":"policies/security-policy/#shared-office-technology","title":"Shared Office Technology","text":"<ol> <li>Conference rooms are equipped with workstations for presentations and conference calls. Guest accounts are available, but are restricted and all information from the session is deleted on logout.</li> <li>All shared office technology is either protected by a password (conference room computer) or locked when not in use.</li> <li>It is common for Caktus employees to use shared tablets, phones, and computers for communicating with clients, running meetings, and performing quality assurance testing. While using these shared computers please follow the following best practices:<ol> <li>Use your own authentication credentials rather than a shared login when possible</li> <li>Only access the sites needed to do your work</li> <li>Lock the screen of the computer when it is not in use</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#confidential-information","title":"Confidential Information","text":"<ol> <li>You may access, use or share confidential information only to the extent it is authorized and necessary to fulfill your assigned job duties.</li> <li>Storage<ol> <li>Confidential information stored on electronic and computing devices whether owned or leased by Caktus, the employee or a third party, remains the sole property of Caktus or its clients.</li> <li>Confidential information should only ever be stored or transferred via workstations, client servers, Dropbox, Google Docs, email, and paper.<ol> <li>High Security Projects: Only workstations and client servers.</li> </ol> </li> <li>USB flash drives, SD cards, and portable hard drives should only be used for temporary storage (less than a day) and should be securely wiped once the transfer is completed.</li> </ol> </li> <li>Deletion<ol> <li>When finished with client projects, all confidential information should be deleted and destroyed.</li> <li>All Caktus maintained storage that is retired from use will be securely wiped and all paper documents should be shredded when they are no longer needed.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#accounts-authentication-secrets","title":"Accounts, Authentication &amp; Secrets","text":"<ol> <li>Authentication and Accounts<ol> <li>If it is possible to authenticate via your Caktus Google account, using 2-factor authentication, or via stored SSH keys, these methods are always preferred to simple password authentication.</li> <li>Multi-factor authentication is recommended for all services that support it and is required for specific services at Caktus. The required services and their rollout schedule can be found on Caktus Security: MFA/2FA Rollout Schedule.<ol> <li>Caktus believes the best MFA is the one you use. Hardware authentication devices, such as Yubikeys, are available and can be provided to Caktus employees upon request.</li> <li>It may be preferable for some accounts, such as your Google Account, to enable several MFA options, so it\u2019s still possible to log into accounts without using your hardware key.</li> <li>If a service offers multiple MFA options, we recommend choosing either a Yubikey or Authenticator app rather than SMS.</li> </ol> </li> <li>When possible, accounts should be created for each individual person who uses a system, rather than using shared authentication credentials.</li> </ol> </li> <li>Passwords<ol> <li>Passwords used for Caktus-related accounts should be generated programmatically (1password, pwgen, etc.) by tools that create random passwords and should be at least eight characters long. Here\u2019s an example using the command line tool: pwgen --secure --symbols --numerals 12</li> <li>Passwords should be stored in Caktus\u2019 Enterprise 1password account. If this isn\u2019t possible, then Keepass or written on paper is acceptable. If they are written down on paper, the password should be kept in a secure location and should not be kept with other authentication information such as what the password is for or a user name.</li> <li>Passwords should only be communicated via secure channels of communication (1Password) or in person, and with other authentication information (e.g. user name) sent via a second means of secure communication.</li> <li>Passwords should never be stored or transmitted in plain text.</li> </ol> </li> <li>Personal account and data restrictions<ol> <li>Accessing Caktus data from personal accounts is prohibited. Data and account privileges should never be shared with personal accounts. For example, never share Caktus Google Drive data with your personal Google account.</li> <li>Using your Caktus email address with accounts intended for personal use is prohibited. Accounts associated with Caktus email addresses should only be used for Caktus-related work.</li> <li>Web access to personal accounts (e.g. Gmail) is only allowed from a separate browser profile to help mitigate accidental cross-pollination of data.</li> <li>Storing Caktus and personal data within the same 3rd party account (e.g. Dropbox) is prohibited, except for open source repositories, package managers, and CI tools.</li> <li>You may use personal accounts to facilitate auxiliary business processes, such as booking a reimbursable flight on Delta, so long as the account will never have access to client or Caktus IP.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#sharing-secrets-with-caktus","title":"Sharing secrets with Caktus","text":"<p>Whenever possible, we try to avoid communicating passwords (or other secrets) directly. Some ways to avoid it:</p> <ul> <li>Grant access to us via our existing accounts. For example, give our Github accounts access to your repositories on Github, or share Google Drive documents with our Google accounts (our xxx@caktusgroup.com addresses).</li> <li>Create new accounts under our email addresses, then let us set our own passwords, possibly using the usual \u201creset password\u201d mechanism.</li> </ul> <p>Both of these methods preserve security by not sharing a password at all.</p> <p>But sometimes it\u2019s unavoidable that you need to send us information that needs to be kept secret. Here are our preferred ways of doing that, in order:</p> <ol> <li>Share with us through a secure system like 1Password (our preference), PassPack, or anything similar to those. If you don't have an account yet, you can share a secret with us via LastPass as follows:<ol> <li>Navigate to https://lastpass.com/create_account.php and create a new account</li> <li>Once you're logged in, create a new \"Secure Note\" via the button in the bottom right corner</li> <li>Copy and paste your secret into the note (this is generally easier than attaching the file, which requires a \"binary extension\" on some computers)</li> <li>Under \"Advanced Settings,\" check the box titled \"Require Password Reprompt\"</li> <li>Give the note a name and save it</li> <li>Click on the share/people icon on the new note</li> <li>Share it with the email address of the individual at Caktus you are corresponding with</li> <li>You may be prompted to verify your own email address, if you haven't yet</li> </ol> </li> <li>Share with us using the site https://onetimesecret.com (for passwords or other secrets) or https://send.firefox.com (for files). It works like this:<ol> <li>Go to the site, type anything you want in a text field (e.g. password, secret key, whatever) or upload a file, and save it. A link will be displayed on the next page that you can email to us. We immediately click on the link when we get it, and the secret (or file) will be shown to us and immediately deleted from the site. Since it\u2019s deleted as soon as we read it, nobody else can read it, even if they somehow get access to the email message with the link. Or if someone does that and beats us to it, when we try to read it we\u2019ll find that it\u2019s already deleted, know that something bad has happened, and let you know to immediately change the password.</li> <li>It\u2019s still a good idea to put in just the password or secret, and not enough other information for someone who got hold of what you put on the site to know what that password is for. If you don\u2019t want to use any of these mechanisms, talk to us and we\u2019ll work out something.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#server-maintenance","title":"Server Maintenance","text":"<ol> <li>Regular maintenance of supported servers will be performed including regular security updates using automated tools.</li> <li>Encryption<ol> <li>Encryption will always be enabled for confidential data in transit through SSH and HTTPS connections.</li> <li>Servers as required have their data secured at rest using GPG encrypted files, and LUKS whole disk encryption.</li> </ol> </li> <li>Backups and Logs<ol> <li>Backups are stored on a secure and updated FreeNAS computer stored in a locked server closet.</li> <li>Logs are stored centrally for each computer including security related daemon logs &amp; login details.</li> <li>All backups and logs are stored for a minimum of 12 months.</li> </ol> </li> </ol>"},{"location":"policies/security-policy/#web-application-security","title":"Web Application Security","text":"<p>The Caktus Security Policies and Best Practices should be followed on all software development projects developed by Caktus.</p>"},{"location":"policies/security-policy/#special-procedures","title":"Special Procedures","text":""},{"location":"policies/security-policy/#protected-health-information-phi","title":"Protected Health Information (PHI)","text":"<p>From time to time Caktus may take on projects that are required to be HIPAA compliant in that they involve Personal Health Information (PHI). In these instances there are a number of project specific best practices that must be adhered to in order to comply with the letter and intent of the HIPAA regulations and maintain patient data in the strictest confidence. The overall goals of these best practices are to not access any PHI unless doing so is unavoidable for one's job function and if access PHI is unavoidable, transferring, storing, and accessing it in a secure way.</p> <p>Project Specific Risk Analysis </p> <p>First, a project specific risk analysis should be created in consultation with the HIPAA compliance officer, project System Administrator, and project Development Lead. This document should document all possible natural, environmental, and human threats to the security of PHI and how they will be addressed. Furthermore, if it is decided not to address a possible PHI threat, then justification must be provided. This Risk Analysis should be updated annually for ongoing projects or whenever there is a significant change to the project scope or management of PHI.</p> <p>Authorization </p> <p>A list of Caktus workers and Caktus directed third parties on the project with access to PHI will be maintained by the Project Manager. All changes in the list must be approved in writing by the HIPAA compliance officer. This will include adding new team members as well as removing team members as soon as their job responsibilities no longer require access to PHI. Included in this notification should be the specific reasons and details of the person\u2019s access to PHI. The HIPAA compliance officer will review the employee\u2019s file for significant lapses in respect for client\u2019s confidentiality before approving their access to any PHI.</p> <p>Sanctions </p> <p>If project team members are found to be out of compliance with HIPAA compliant PHI procedures, they will be immediately removed from the project using the termination procedure and the incident will be reported to Human Resources for further evaluation.</p> <p>Training </p> <p>All team members on projects related to PHI must complete a training module if they have not completed a training in the last year. If someone currently with access to PHI has not completed training within the last year, they must also complete a training module. The completion of trainings should be shared with the HIPAA compliance officer for their record keeping.</p> <p>Communication &amp; Storage </p> <p>PHI should only be communicated over a network via SSH and HTTPS connections. Email, Dropbox, Google Apps, and chat should never be used to communicate PHI. PHI should not be transmitted via or stored on portable physical media (CDROM, DVD, portable hard drive, USB jump drive, SD card, etc.) due to the possibility of loss and the details of cleaning or disposing of the media after use. The only media that should hold PHI are encrypted workstation hard drives, backup storage, and media controlled by approved third party hosting providers.</p> <p>Shared and personal devices should never be used to access systems containing PHI. If mobile devices are needed for application testing, they should be exclusive to the project and their storage wiped clean once they are no longer needed for the project.</p> <p>All paper project notes and communications relating to the system used in the development process should be kept locked up when not in use and shredded once they are no longer needed.</p> <p>Business Associates Agreements with Subcontractors</p> <p>All subcontractors with access to PHI including independent contractors, hosting providers, and communications providers must sign BAA agreements with Caktus prior to having access to any PHI.</p> <p>Special Development Practices</p> <p>The following best practices are specific to projects handling PHI in addition to the standard Security Policies and Best Practices.</p> <ol> <li>Automatic logoff</li> <li>Unique user IDs</li> <li>Password recovery procedures</li> <li>Audit controls</li> <li>Isolation of clearinghouse functionality</li> <li>Do not email production errors<ol> <li>Forms contain PHI -&gt; Requests contain -&gt; Email contains PHI</li> <li>Log errors and send email notifications of errors</li> </ol> </li> <li>\u201cPersonal Identifying Information,\u201d as defined by the North Carolina Identity Theft Protection Act of 2005. This includes employer tax ID numbers, drivers' license numbers, passport numbers, SSNs, state identification card numbers, credit/debit card numbers, banking account numbers, PIN codes, digital signatures, biometric data, fingerprints, passwords, and any other numbers or info that can be used to access a person's financial resources. </li> <li>\u201cProtected Health Information\u201d as defined by HIPAA </li> <li>Student \u201ceducation records,\u201d as defined by the Family Educational Rights and Privacy Act (FERPA) </li> <li>\u201cCustomer record information,\u201d as defined by the Gramm Leach Bliley Act (GLBA) </li> <li>\u201cCard holder data,\u201d as defined by the Payment Card Industry (PCI) Data Security Standard </li> <li>Confidential \u201cpersonnel information,\u201d as defined by the State Personnel Act Information that is deemed to be confidential in accordance with the North Carolina Public Records Act </li> </ol>"},{"location":"policies/security-policy/#security-team","title":"Security Team","text":""},{"location":"policies/security-policy/#purpose","title":"Purpose","text":"<p>Security can take many forms: from PCI compliance, server firewalls, and encryption to security patches and incident response guidelines. Best practices and procedures can guide development to build secure web applications. The Caktus Security Team creates team best practices and procedures, facilitates knowledge sharing, and helps with responding to security incidents. We strive to:</p> <ul> <li>Proactively research and implement improvements to further Caktus\u2019 security procedures</li> <li>Maintain the Caktus Security Policy and best practices</li> <li>Monitor for security exploits, review severity, and inform teams</li> <li>Recommend solutions to team-raised security questions</li> <li>Guide teams through security incident reports and responses</li> </ul>"},{"location":"policies/security-policy/#process","title":"Process","text":"<ul> <li>Triage backlog into 2 lanes:<ul> <li>Immediate Support</li> <li>Ongoing Initiatives</li> </ul> </li> <li>Weekly 10-minute standups<ul> <li>Determine if any newly added issues should be prioritized</li> <li>Check-in on WIP issues (always limit to 4)</li> </ul> </li> </ul>"},{"location":"policies/security-policy/#policy-maintenance-and-compliance","title":"Policy Maintenance and Compliance","text":"<ol> <li>Maintenance and Compliance<ol> <li>The Security Team maintains the policies and procedures related to day to day security and incident responses at Caktus. They are also responsible for the implementation of the policies at Caktus and compliance with relevant regulations.</li> <li>Caktus will verify compliance to this policy through various methods, including but not limited to, internal and external audits and feedback to the Security Team.</li> </ol> </li> <li>Risk Analysis<ol> <li>Quarterly, a cross functional team including representatives from Human Resources, Systems Administration, Software Development, and Operations will meet to review the current policies and procedures and their implementation.</li> <li>Annually the HealthIT.gov risk assessment tool will be used to create a new risk assessment document.</li> <li>The systems administration team is determined to be notified about new security threats by following the security lists and Common Vulnerabilities and Exposures (CVE) announcements related to the specific software stack employed by projects at Caktus.</li> </ol> </li> </ol>"},{"location":"reference/from-caktus-with-love/","title":"From Caktus with Love","text":""},{"location":"reference/from-caktus-with-love/#growth-suggestions-from-cakti-to-cakti","title":"Growth suggestions from cakti to cakti","text":"<p>** Command Line **  I highly suggest this command line class by instructor Colt Steele on Udemy. The class covers basic commands such as navigating your system, creating folders, removing files and more important and interesting conceps such as piping, grep, permission and how to alter them, modifying our own command lines, and more. While the class is lenghty, the instructor keeps it fun. There's a lot of power to the command line, and this course helped me tap a bit more into it.</p> <p>Ronard \ud83c\udf35</p> <p>** Save Yourself **  If you use a nix style command line with any frequency and especially if you tend to be heavy handed with <code>rm -rf</code> do yourself a favor and install <code>trash-cli</code> on Debian derivatives, and add an alias to your shell's <code>rc</code> file: <code>alias rm=\"trash\"</code>. If you ever make a mistake like I just did you can recover the files.</p> <ul> <li>Ubuntu</li> <li>Mac</li> </ul> <p>Jeremy \ud83c\udf35</p> <p>** Disable Homebrew auto updates **  Have you ever inocently tried install a package using Homebrew and before you know it, Homebrew updates all of your dependecies? The result, all of your virtual environments are broken &amp; much more.  Well, there is a way to avoid that - rather than <code>brew install &lt;formula&gt;</code>, run <code>HOMEBREW_NO_AUTO_UPDATE=1 brew install &lt;formula&gt;</code></p> <p>Click here for more info. Credit to Dmitriy for the discovery.</p> <p>Ronard \ud83c\udf35</p> <p>** Google Meet and Macs **  For anybody on a Mac who has had problems sharing their screen on a google meet, the following fixed it for me. I had to disallow Chrome's access to record my screen, then allow it again.</p> <ul> <li>Go to settings --&gt; Security &amp; Privacy --&gt; Privacy tab --&gt; Camera on left side</li> <li>There you can disallow, then allow again.</li> </ul> <p>Michael \ud83c\udf35</p> <p>** The extension for YAML files is .yaml **  In the great YAML debate of 2022 Cakti agreed that .yaml was the correct extension for YAML files. </p> <p>Henceforth new projects at Caktus will use .yaml and old projects will be converted to .yaml as time allows.</p> <p>Scott \ud83c\udf35</p> <p>** If changing from a Mac to another Mac **  The Migration Assistant tool on Mac is extremely easy. Most files will be transfered, but there may be some stragglers that don't make the move. Use the M1 and M2 setup in documentation to make sure all the files you need are present. You will likely need to create and manually move your SSH Key, but we recomend you generate a new one as it is best practice to rotate these keys over time. You will have to update your Key with your projects as well. </p> <p>Follow the instructions here to use the [Migration Assitant Tool] (https://support.apple.com/en-us/HT204350).</p> <p>Follow the instructions here for generating a new [SSH Key] (https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account)</p>"},{"location":"reference/info/","title":"Editing","text":"<p>As stated in the welcome page you may click the pencil \u270f\ufe0f on the top right of each page to edit content on github, but you may also clone the repository, install the requirements, and edit using your IDE of choice.</p> <p>Just in case you need it, here's a quick overview and some helpful tips on the markdown sytanx. </p>"},{"location":"reference/info/#slack-channel","title":"Slack Channel","text":"<p>To keep people aware of new documentation submissions, we created ** #caktus-documentation **. Join the slack channel to stay on the \u27b0.</p> <p></p>"},{"location":"reference/info/#from-caktus-with-love","title":"From Caktus with Love","text":"<p>The internet has a lot of content, but not all of it is great. However, sometimes we stumble upon content that is just exceptional, that is where the idea of From Caktus with Love came in. It is a place to display suggestion for other cakti on the exceptional content we find, be it technical or non-technical.</p>"}]}